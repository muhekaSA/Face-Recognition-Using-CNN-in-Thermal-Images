{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c5102e-b8fb-43e1-9e5b-309a111ea058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9675eeb-7ddf-4654-a4e9-e14be13858e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 765/765 [00:00<00:00, 1818.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 128, 128, 1)\n",
      "(115, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def label_name(image_name):\n",
    "    name = image_name.split('.')[-3] #eka image\n",
    "    if name==\"eka\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"pakesa\":\n",
    "        return np.array([0,1,0])\n",
    "def my_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"coba\")):\n",
    "        path=os.path.join(\"coba\",img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (128,128))\n",
    "        data.append([np.array(img_data), label_name(img)])\n",
    "    shuffle(data)  \n",
    "    return data\n",
    "data = my_data()\n",
    "\n",
    "train = data[:650]  \n",
    "test = data[650:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,128,128,1)\n",
    "print(X_train.shape)\n",
    "y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,128,128,1)\n",
    "print(X_test.shape)\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07420048-cfc2-4121-90b5-6c4e80ed5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train : {}'.format(X_train[:]))\n",
    "print('Y-train shape: {}'.format(y_train))\n",
    "print('x_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92f96d2-c263-4f25-9e2f-0b6b7c9ebfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\deprecation.py:549: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "---------------------------------\n",
      "Run id: FRS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 650\n",
      "Validation samples: 115\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 3) for Tensor 'outlayer/Y:0', which has shape '(?, 50)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15652/919728764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outlayer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/tmp/tflearn_logs/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_checkpoints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensorboard_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"FRS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    204\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mretrieve_data_preprocessing_and_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    342\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                                                        show_metric)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                             \u001b[1;31m# Update training state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[1;32m--> 828\u001b[1;33m                                              feed_batch)\n\u001b[0m\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[1;31m# Retrieve loss value from summary string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 968\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1168\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (64, 3) for Tensor 'outlayer/Y:0', which has shape '(?, 50)'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "convnet = input_data(shape=[128,128,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu', name='conv1')\n",
    "# 32 = Filters, 5 = Stride represent the every single move of pixels\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu', name='conv2')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu', name='conv3')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu', name='conv5')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu', name='conv6')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu', name='conv7')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = fully_connected(convnet, 1024, activation='relu', name='FC1')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax', name='FC2')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy', name='outlayer')\n",
    "model = tflearn.DNN(convnet, checkpoint_path='/tmp/tflearn_logs/',max_checkpoints=1,tensorboard_verbose=3)\n",
    "history=model.fit(X_train, y_train, n_epoch=3, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\", callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c1ed9-7598-44e1-a278-59831d937672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import six\n",
    "\n",
    "def display_convolutions(model, layer, padding=2, filename=''):\n",
    "    if isinstance(layer, six.string_types):\n",
    "        vars = tflearn.get_layer_variables_by_name(layer)\n",
    "        variable = vars[0]\n",
    "    else:\n",
    "        variable = layer.W\n",
    "\n",
    "    data = model.get_weights(variable)\n",
    "\n",
    "    # N is the total number of convolutions\n",
    "    N = data.shape[2] * data.shape[3]\n",
    "    print('There are {} filters'.format(N))\n",
    "\n",
    "    # Ensure the resulting image is square\n",
    "    filters_per_row = int(np.ceil(np.sqrt(N)))\n",
    "    # Assume the filters are square\n",
    "    filter_size = data.shape[0]\n",
    "    # Size of the result image including padding\n",
    "    result_size = filters_per_row * (filter_size + padding) - padding\n",
    "    # Initialize result image to all zeros\n",
    "    result = np.zeros((result_size, result_size))\n",
    "\n",
    "    # Tile the filters into the result image\n",
    "    filter_x = 0\n",
    "    filter_y = 0\n",
    "    for n in range(data.shape[3]):\n",
    "        for c in range(data.shape[2]):\n",
    "            if filter_x == filters_per_row:\n",
    "                filter_y += 1\n",
    "                filter_x = 0\n",
    "            for i in range(filter_size):\n",
    "                for j in range(filter_size):\n",
    "                    result[filter_y * (filter_size + padding) + i, filter_x * (filter_size + padding) + j] = \\\n",
    "                        data[i, j, c, n]\n",
    "            filter_x += 1\n",
    "\n",
    "    # Normalize image to 0-1\n",
    "    min = result.min()\n",
    "    max = result.max()\n",
    "    result = (result - min) / (max - min)\n",
    "\n",
    "    # Plot figure\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result, cmap='gray', interpolation='nearest')\n",
    "\n",
    "    # Save plot if filename is set\n",
    "    if filename != '':\n",
    "        plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c9116-0cc8-4623-b8ad-ee061f084936",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae85060-9561-48a9-a1a8-f6634c971f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3857775-f3b9-484c-ba0f-e3c915fe2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110afa5-d82a-4547-9c1d-9f9e44bb9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d578c-c3dd-443b-8f3e-a3f456e8930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0db08-7dcd-4c4e-9abb-e81f6d4dff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"Image for Visualization\")):\n",
    "        path = os.path.join(\"Image for Visualization\", img)\n",
    "        img_num = img.split('_')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE )\n",
    "        img_data = cv2.resize(img_data, (128,128))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata\n",
    "Vdata = data_for_visualization()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aedbb-89d1-402e-80df-e9f227d06bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(128,128,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'eka'\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'pak esa'\n",
    "    elif np.argmax(model_out) == 2:\n",
    "        my_label = 'Bowo'\n",
    "    else:\n",
    "        my_label = 'Tidak Dikenali'\n",
    "        \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "    \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bf763e-39aa-4269-9d8b-eaf565582968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f5f32-41de-41b0-8ab0-381e3a5d0431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
