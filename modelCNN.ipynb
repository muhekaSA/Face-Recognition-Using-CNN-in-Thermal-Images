{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c5102e-b8fb-43e1-9e5b-309a111ea058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muham\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9675eeb-7ddf-4654-a4e9-e14be13858e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1109/1109 [00:00<00:00, 1944.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 128, 128, 1)\n",
      "(209, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def label_name(image_name):\n",
    "    name = image_name.split('.')[-3] #eka image\n",
    "    if name==\"eka\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"pakesa\":\n",
    "        return np.array([0,1,0])\n",
    "def my_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"dataset perpus\")):\n",
    "        path=os.path.join(\"dataset perpus\",img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (128,128))\n",
    "        data.append([np.array(img_data), label_name(img)])\n",
    "    shuffle(data)  \n",
    "    return data\n",
    "data = my_data()\n",
    "\n",
    "train = data[:900]  \n",
    "test = data[900:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,128,128,1)\n",
    "print(X_train.shape)\n",
    "y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,128,128,1)\n",
    "print(X_test.shape)\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07420048-cfc2-4121-90b5-6c4e80ed5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train : {}'.format(X_train[:]))\n",
    "print('Y-train shape: {}'.format(y_train))\n",
    "print('x_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92f96d2-c263-4f25-9e2f-0b6b7c9ebfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1499  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 17.195s\n",
      "| Adam | epoch: 100 | loss: 0.00000 - acc: 1.0000 -- iter: 896/900\n",
      "Training Step: 1500  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 19.689s\n",
      "| Adam | epoch: 100 | loss: 0.00000 - acc: 1.0000 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 900/900\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "convnet = input_data(shape=[128,128,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu', name='conv1')\n",
    "# 32 = Filters, 5 = Stride represent the every single move of pixels\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu', name='conv2')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu', name='conv3')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 256, 5, activation='relu', name='conv4')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu', name='conv5')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu', name='conv6')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu', name='conv7')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = fully_connected(convnet, 1024, activation='relu', name='FC1')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax', name='FC2')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy', name='outlayer')\n",
    "model = tflearn.DNN(convnet, checkpoint_path='/tmp/tflearn_logs/',max_checkpoints=1,tensorboard_verbose=3)\n",
    "model.fit(X_train, y_train, n_epoch=100, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\", callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027c1ed9-7598-44e1-a278-59831d937672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import six\n",
    "\n",
    "def display_convolutions(model, layer, padding=2, filename=''):\n",
    "    if isinstance(layer, six.string_types):\n",
    "        vars = tflearn.get_layer_variables_by_name(layer)\n",
    "        variable = vars[0]\n",
    "    else:\n",
    "        variable = layer.W\n",
    "\n",
    "    data = model.get_weights(variable)\n",
    "\n",
    "    # N is the total number of convolutions\n",
    "    N = data.shape[2] * data.shape[3]\n",
    "    print('There are {} filters'.format(N))\n",
    "\n",
    "    # Ensure the resulting image is square\n",
    "    filters_per_row = int(np.ceil(np.sqrt(N)))\n",
    "    # Assume the filters are square\n",
    "    filter_size = data.shape[0]\n",
    "    # Size of the result image including padding\n",
    "    result_size = filters_per_row * (filter_size + padding) - padding\n",
    "    # Initialize result image to all zeros\n",
    "    result = np.zeros((result_size, result_size))\n",
    "\n",
    "    # Tile the filters into the result image\n",
    "    filter_x = 0\n",
    "    filter_y = 0\n",
    "    for n in range(data.shape[3]):\n",
    "        for c in range(data.shape[2]):\n",
    "            if filter_x == filters_per_row:\n",
    "                filter_y += 1\n",
    "                filter_x = 0\n",
    "            for i in range(filter_size):\n",
    "                for j in range(filter_size):\n",
    "                    result[filter_y * (filter_size + padding) + i, filter_x * (filter_size + padding) + j] = \\\n",
    "                        data[i, j, c, n]\n",
    "            filter_x += 1\n",
    "\n",
    "    # Normalize image to 0-1\n",
    "    min = result.min()\n",
    "    max = result.max()\n",
    "    result = (result - min) / (max - min)\n",
    "\n",
    "    # Plot figure\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result, cmap='gray', interpolation='nearest')\n",
    "\n",
    "    # Save plot if filename is set\n",
    "    if filename != '':\n",
    "        plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c9116-0cc8-4623-b8ad-ee061f084936",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae85060-9561-48a9-a1a8-f6634c971f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3857775-f3b9-484c-ba0f-e3c915fe2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110afa5-d82a-4547-9c1d-9f9e44bb9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d578c-c3dd-443b-8f3e-a3f456e8930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, 'conv5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0db08-7dcd-4c4e-9abb-e81f6d4dff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"Image for Visualization\")):\n",
    "        path = os.path.join(\"Image for Visualization\", img)\n",
    "        img_num = img.split('_')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE )\n",
    "        img_data = cv2.resize(img_data, (128,128))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata\n",
    "Vdata = data_for_visualization()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aedbb-89d1-402e-80df-e9f227d06bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(128,128,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'eka'\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'pak esa'\n",
    "    elif np.argmax(model_out) == 2:\n",
    "        my_label = 'Bowo'\n",
    "    else:\n",
    "        my_label = 'Tidak Dikenali'\n",
    "        \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "    \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf763e-39aa-4269-9d8b-eaf565582968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f5f32-41de-41b0-8ab0-381e3a5d0431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
